# -*- coding: utf-8 -*-
"""
EcomTrendAI çµ±åˆå®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ãƒ‡ãƒ¼ã‚¿åé›† â†’ ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ â†’ ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ ã‚’ä¸€æ‹¬å®Ÿè¡Œ
æ—¥æ¬¡è‡ªå‹•å®Ÿè¡Œç”¨ã®ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
"""

import argparse
import sys
import time
from datetime import datetime
from pathlib import Path
from typing import Optional

from loguru import logger

# ãƒ­ã‚°è¨­å®š
log_dir = Path(__file__).parent.parent / "logs"
log_dir.mkdir(exist_ok=True)
log_file = log_dir / f"ecomtrend_{datetime.now().strftime('%Y%m%d')}.log"

logger.remove()  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒãƒ³ãƒ‰ãƒ©å‰Šé™¤
logger.add(sys.stderr, level="INFO", format="{time:HH:mm:ss} | {level} | {message}")
logger.add(log_file, level="DEBUG", rotation="10 MB", encoding="utf-8")


def run_scraper(categories: list[str], limit: int) -> int:
    """
    ãƒ‡ãƒ¼ã‚¿åé›†ã‚’å®Ÿè¡Œ

    Args:
        categories: åé›†å¯¾è±¡ã‚«ãƒ†ã‚´ãƒª
        limit: ã‚«ãƒ†ã‚´ãƒªã‚ãŸã‚Šã®å–å¾—ä»¶æ•°

    Returns:
        åé›†ã—ãŸå•†å“æ•°
    """
    from scraper import AmazonScraper, DataSaver

    logger.info("=== ãƒ‡ãƒ¼ã‚¿åé›†é–‹å§‹ ===")
    scraper = AmazonScraper()
    saver = DataSaver()

    all_products = []

    for category in categories:
        logger.info(f"ã‚«ãƒ†ã‚´ãƒª: {category}")
        products = scraper.fetch_movers_shakers(category, limit=limit)
        all_products.extend(products)
        time.sleep(3)  # ã‚«ãƒ†ã‚´ãƒªé–“ã®å¾…æ©Ÿ

    if all_products:
        filepath = saver.save_to_csv(all_products)
        logger.info(f"ãƒ‡ãƒ¼ã‚¿ä¿å­˜å®Œäº†: {filepath} ({len(all_products)}ä»¶)")
    else:
        logger.warning("ãƒ‡ãƒ¼ã‚¿ã‚’åé›†ã§ãã¾ã›ã‚“ã§ã—ãŸ")

    return len(all_products)


def run_analyzer() -> tuple[list, dict]:
    """
    ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’å®Ÿè¡Œ

    Returns:
        (å…¨ä½“ãƒˆãƒ¬ãƒ³ãƒ‰, ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰)
    """
    from analyzer import TrendAnalyzer

    logger.info("=== ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æé–‹å§‹ ===")
    analyzer = TrendAnalyzer()

    trends = analyzer.analyze_trends(top_n=20)
    category_trends = analyzer.analyze_by_category()

    significant = analyzer.detect_significant_movers(threshold=80.0)
    if significant:
        logger.info(f"å¤§å¹…å¤‰å‹•å•†å“: {len(significant)}ä»¶")

    logger.info(f"ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æå®Œäº†: {len(trends)}ä»¶")
    return trends, category_trends


def run_reporter(trends: list, category_trends: dict) -> tuple[list[Path], Optional[Path], Optional[Path]]:
    """
    ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆã‚’å®Ÿè¡Œ

    Args:
        trends: å…¨ä½“ãƒˆãƒ¬ãƒ³ãƒ‰
        category_trends: ã‚«ãƒ†ã‚´ãƒªåˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰

    Returns:
        (ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ä¸€è¦§, MDãƒ‘ã‚¹, HTMLãƒ‘ã‚¹)
    """
    from analyzer import ReportGenerator
    from reporter import HTMLReportGenerator

    logger.info("=== ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆé–‹å§‹ ===")
    reports = []

    # Markdownãƒ¬ãƒãƒ¼ãƒˆ
    md_reporter = ReportGenerator()
    md_path = md_reporter.generate_markdown_report(trends, category_trends)
    reports.append(md_path)

    # HTMLãƒ¬ãƒãƒ¼ãƒˆ
    html_reporter = HTMLReportGenerator()
    html_path = html_reporter.generate(trends, category_trends)
    reports.append(html_path)

    logger.info(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå®Œäº†: {len(reports)}ä»¶")
    return reports, md_path, html_path


def run_distributor(
    trends: list,
    md_path: Optional[Path] = None,
    html_path: Optional[Path] = None
) -> dict[str, bool]:
    """
    ãƒ¬ãƒãƒ¼ãƒˆé…ä¿¡ã‚’å®Ÿè¡Œ

    Args:
        trends: ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªã‚¹ãƒˆï¼ˆã‚µãƒãƒªãƒ¼ç”Ÿæˆç”¨ï¼‰
        md_path: Markdownãƒ¬ãƒãƒ¼ãƒˆãƒ‘ã‚¹
        html_path: HTMLãƒ¬ãƒãƒ¼ãƒˆãƒ‘ã‚¹

    Returns:
        é…ä¿¡çµæœ
    """
    from distributor import ReportDistributor, create_summary_for_notification

    logger.info("=== ãƒ¬ãƒãƒ¼ãƒˆé…ä¿¡é–‹å§‹ ===")

    distributor = ReportDistributor()

    if not distributor.distributors:
        logger.info("é…ä¿¡å…ˆãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€é…ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—")
        return {}

    # ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã¯ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é…ä¿¡
    if md_path and md_path.exists():
        results = distributor.distribute_from_files(md_path, html_path)
    else:
        # ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„å ´åˆã¯ã‚µãƒãƒªãƒ¼ã®ã¿é…ä¿¡
        subject = f"ğŸ“Š EcomTrendAI ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ¬ãƒãƒ¼ãƒˆ - {datetime.now().strftime('%Y%m%d')}"
        summary = create_summary_for_notification(trends, top_n=5)
        results = distributor.distribute(subject, summary)

    success = sum(1 for v in results.values() if v)
    logger.info(f"é…ä¿¡å®Œäº†: {success}/{len(results)} æˆåŠŸ")

    return results


def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ"""
    parser = argparse.ArgumentParser(description="EcomTrendAI çµ±åˆå®Ÿè¡Œ")
    parser.add_argument(
        "--categories",
        nargs="+",
        default=["electronics", "computers", "videogames", "toys"],
        help="åé›†å¯¾è±¡ã‚«ãƒ†ã‚´ãƒªï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: electronics computers videogames toysï¼‰",
    )
    parser.add_argument(
        "--limit",
        type=int,
        default=20,
        help="ã‚«ãƒ†ã‚´ãƒªã‚ãŸã‚Šã®å–å¾—ä»¶æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 20ï¼‰",
    )
    parser.add_argument(
        "--skip-scrape",
        action="store_true",
        help="ãƒ‡ãƒ¼ã‚¿åé›†ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã§åˆ†æã®ã¿ï¼‰",
    )
    parser.add_argument(
        "--distribute",
        action="store_true",
        help="ãƒ¬ãƒãƒ¼ãƒˆã‚’Email/Webhookã§é…ä¿¡ï¼ˆ.envè¨­å®šå¿…é ˆï¼‰",
    )
    parser.add_argument(
        "--skip-distribute",
        action="store_true",
        help="ãƒ¬ãƒãƒ¼ãƒˆé…ä¿¡ã‚’ã‚¹ã‚­ãƒƒãƒ—",
    )

    args = parser.parse_args()

    start_time = datetime.now()
    logger.info("=" * 60)
    logger.info(f"EcomTrendAI æ—¥æ¬¡å®Ÿè¡Œé–‹å§‹: {start_time.strftime('%Y-%m-%d %H:%M:%S')}")
    logger.info("=" * 60)

    try:
        # Step 1: ãƒ‡ãƒ¼ã‚¿åé›†
        product_count = 0
        if not args.skip_scrape:
            product_count = run_scraper(args.categories, args.limit)
            if product_count == 0:
                logger.error("ãƒ‡ãƒ¼ã‚¿åé›†å¤±æ•—ã€‚å‡¦ç†ã‚’ä¸­æ­¢ã—ã¾ã™ã€‚")
                return 1
        else:
            logger.info("ãƒ‡ãƒ¼ã‚¿åé›†ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ--skip-scrapeï¼‰")

        # Step 2: ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ
        trends, category_trends = run_analyzer()
        if not trends:
            logger.error("åˆ†æå¯¾è±¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
            return 1

        # Step 3: ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        reports, md_path, html_path = run_reporter(trends, category_trends)

        # Step 4: ãƒ¬ãƒãƒ¼ãƒˆé…ä¿¡ï¼ˆ--distributeã¾ãŸã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ä½œï¼‰
        distribution_results = {}
        if args.distribute and not args.skip_distribute:
            distribution_results = run_distributor(trends, md_path, html_path)

        # å®Œäº†ã‚µãƒãƒªãƒ¼
        elapsed = (datetime.now() - start_time).total_seconds()
        logger.info("=" * 60)
        logger.info("å®Ÿè¡Œå®Œäº†ã‚µãƒãƒªãƒ¼")
        logger.info(f"  åé›†å•†å“æ•°: {product_count}")
        logger.info(f"  ãƒˆãƒ¬ãƒ³ãƒ‰ä»¶æ•°: {len(trends)}")
        logger.info(f"  ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ: {len(reports)}ä»¶")
        if distribution_results:
            success = sum(1 for v in distribution_results.values() if v)
            logger.info(f"  é…ä¿¡æˆåŠŸ: {success}/{len(distribution_results)}")
        logger.info(f"  å®Ÿè¡Œæ™‚é–“: {elapsed:.1f}ç§’")
        logger.info("=" * 60)

        # ã‚³ãƒ³ã‚½ãƒ¼ãƒ«å‡ºåŠ›ï¼ˆç°¡æ˜“ï¼‰
        print("\nã€æœ¬æ—¥ã®ãƒˆãƒƒãƒ—5ã€‘")
        for i, t in enumerate(trends[:5], 1):
            print(f"{i}. {t.name[:40]}... (+{t.rank_change_percent:.0f}%)")
        print(f"\nè©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ: {reports[0] if reports else 'ãªã—'}")

        return 0

    except Exception as e:
        logger.exception(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        return 1


if __name__ == "__main__":
    sys.exit(main())
